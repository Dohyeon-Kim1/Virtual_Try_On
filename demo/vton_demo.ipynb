{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Enviroment Set-up**"
      ],
      "metadata": {
        "id": "3aKv5zMZVokc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-MqGE39dUEj"
      },
      "outputs": [],
      "source": [
        "## git clone repository\n",
        "!git clone -q https://github.com/Dohyeon-Kim1/Virtual_Try_On.git VTON\n",
        "\n",
        "## set directory\n",
        "%cd /content/VTON\n",
        "\n",
        "## install required pacakges\n",
        "!pip install -q accelerate==0.26.1\n",
        "!pip install -q diffusers==0.14.0\n",
        "!pip install -q transformers==4.27.3\n",
        "!pip install -q ftfy==6.1.3\n",
        "!pip install -q clean-fid==0.1.35\n",
        "!pip install -q torchmetrics==1.3.0.post0\n",
        "!pip install -q opencv-contrib-python==4.8.0.76\n",
        "!pip install -q openmim==0.3.8\n",
        "!mim install -q mmcv==2.1.0\n",
        "!mim install -q mmengine==0.10.3\n",
        "!mim install -q mmpose==1.3.1\n",
        "!pip install -q xtcocotools==1.14.3\n",
        "!pip install -q munkres==1.1.4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Inference**"
      ],
      "metadata": {
        "id": "dE_cpZhLWged"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "from inference import Inferencer"
      ],
      "metadata": {
        "id": "JsJSn412dnZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## load inferencer\n",
        "device = \"cuda\"\n",
        "inferencer = Inferencer(device=device)"
      ],
      "metadata": {
        "id": "RO8h-7DkWmei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## load body & cloth image\n",
        "category = \"upper_body\"\n",
        "body_img = Image.open(\"images/body1.jpg\").convert(\"RGB\")\n",
        "cloth_img = Image.open(\"images/upper2.jpg\").convert(\"RGB\")"
      ],
      "metadata": {
        "id": "UKSPV-4JeRS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## fitting cloth\n",
        "output = inferencer.inference(body_img,                      # PIL.Image\n",
        "                              cloth_img,                     # PIL.Image\n",
        "                              category,                      # [\"upper_body\", \"lower_vody\", \"dresses\"]\n",
        "                              guidance_scale=5,              # Float\n",
        "                              num_inference_steps=50)        # Int"
      ],
      "metadata": {
        "id": "0qbMx_6U0OBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## show fitting result\n",
        "display(output)"
      ],
      "metadata": {
        "id": "S4orJTOTYAtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## save fitting result\n",
        "output.save(\"images/output.png\")"
      ],
      "metadata": {
        "id": "6Xq8kFQ0YG0D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}